{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ml](figs/ml_map.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(f'pandas: {pd.__version__}')\n",
    "\n",
    "import numpy as np\n",
    "print(f'numpy: {np.__version__}')\n",
    "\n",
    "import matplotlib\n",
    "print(f'matplotlib: {matplotlib.__version__}')\n",
    "import sklearn\n",
    "print(f'sklearn: {sklearn.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# load processed data\n",
    "dfFV = pd.read_csv(\"titanic_FV.csv\")\n",
    "survived = pd.read_csv(\"survived.csv\", header=None)\n",
    "#convert survived to array of 0s and 1s\n",
    "survived_array = survived.values.flatten().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![proj](figs/proj.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(random_state=7414)\n",
    "pca.fit(dfFV)\n",
    "df_reduced = pca.transform(dfFV)\n",
    "pca_score = pca.explained_variance_ratio_\n",
    "pca_weights = pca.components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Scree Plot: Eigenvalue vs. component number \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"PCA component contribution fall off\")\n",
    "ax.plot(pca_score)\n",
    "ax.set_xlabel(\"Component\")\n",
    "ax.set_ylabel(\"Weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Since drastically falls off by 3rd component, lets plot the first two\n",
    "fig, ax = plt.subplots()\n",
    "#grab all rows of first and second components (columns of df_reduced)\n",
    "ax.scatter(df_reduced[:,0], df_reduced[:,1])\n",
    "ax.set_xlabel(\"component 1\")\n",
    "ax.set_ylabel(\"component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# lets use boolean masks to add class information: 1=True, 0=False\n",
    "# values turns the dataframe into a 2D array, flatten makes it 1D\n",
    "mask = survived_array.astype(bool)\n",
    "yes = df_reduced[mask]\n",
    "no = df_reduced[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#let's check that the above worked\n",
    "yes.shape, no.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(yes[:,0], yes[:,1], label=\"survived\", color=\"g\")\n",
    "ax.scatter(no[:,0], no[:,1], label=\"died\", color=\"r\")                                   \n",
    "ax.set_xlabel(\"component 1\")\n",
    "ax.set_ylabel(\"component 2\")\n",
    "ax.legend(scatterpoints=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#and lets look at what determines the directionality\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2)\n",
    "\n",
    "comp1 = pca_weights.T[0]\n",
    "comp2 = pca_weights.T[1]\n",
    "\n",
    "ax1.bar(range(comp1.shape[0]), comp1, align='center')\n",
    "ax1.set_xticks(range(comp1.shape[0]))\n",
    "ax1.set_xlim(-.5,12.5)\n",
    "ax1.set_ylim(-.8,.8)\n",
    "ax1.set_ylabel(\"X axis\")\n",
    "\n",
    "ax2.bar(range(comp2.shape[0]), comp2, align='center')\n",
    "ax2.set_xticks(range(comp2.shape[0]))\n",
    "ax2.set_xticklabels(dfFV.keys(), rotation=90)\n",
    "ax2.set_xlim(-.5,12.5)\n",
    "ax2.set_ylim(-.8,.8)\n",
    "ax2.set_ylabel(\"Y axis\")\n",
    "\n",
    "fig.subplots_adjust(hspace=0.010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#We can put it all together\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "#rows, #cols, position\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "ax3 = fig.add_subplot(2, 2, 4)\n",
    "\n",
    "#grab all rows of first and second components (columns of df_reduced)\n",
    "ax1.scatter(yes[:,0], yes[:,1], label=\"survived\", color=\"g\")\n",
    "ax1.scatter(no[:,0], no[:,1], label=\"died\", color=\"r\")                                   \n",
    "ax1.set_xlabel(\"component 1\")\n",
    "ax1.set_ylabel(\"component 2\")\n",
    "ax1.legend(scatterpoints=1)\n",
    "\n",
    "#and lets look at what determines the directionality\n",
    "\n",
    "comp1 = pca_weights.T[0]\n",
    "comp2 = pca_weights.T[1]\n",
    "\n",
    "ax2.bar(range(comp1.shape[0]), comp1, align='center')\n",
    "ax2.set_xticks(range(comp1.shape[0]))\n",
    "ax2.set_xlim(-.5,12.5)\n",
    "ax2.set_ylim(-.8,.8)\n",
    "ax2.set_ylabel(\"X axis\")\n",
    "\n",
    "ax3.bar(range(comp2.shape[0]), comp2, align='center')\n",
    "ax3.set_xticks(range(comp2.shape[0]))\n",
    "ax3.set_xticklabels(dfFV.keys(), rotation=90)\n",
    "ax3.set_xlim(-.5,12.5)\n",
    "ax3.set_ylim(-.8,.8)\n",
    "ax3.set_ylabel(\"Y axis\")\n",
    "\n",
    "fig.subplots_adjust(wspace=0.2, hspace=0.010)\n",
    "fig.savefig(\"figs/pca_graphs.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![pcabar](figs/pca_graphs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Challenge\n",
    "=====\n",
    "* What does PCA yield if you only use the categorical variables?\n",
    "* What does PCA yield if you only use the quantative variables?\n",
    "* What does PCA yield if you only use some variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# So not the greatest seperation...new idea?\n",
    "![kmeans](figs/kmeans.gif)\n",
    "source: [Project Rhea: Introduction to Clustering](https://www.projectrhea.org/rhea/index.php/SlectureDavidRunyanCS662Spring14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmean = KMeans(init='k-means++', n_clusters=2, random_state=7414)\n",
    "kmean.fit(dfFV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# What information can we get from KMeans?\n",
    "KMeans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cluster0 = kmean.cluster_centers_[0]\n",
    "cluster1 = kmean.cluster_centers_[1]\n",
    "\n",
    "#built a list 0- # of features\n",
    "inds = np.arange(kmean.cluster_centers_.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.bar(inds, cluster0,width=.5, align='center', label=\"Class 0\")\n",
    "ax.bar(inds+.5, cluster1, width=.5, align='center', color='r',label= \"Class 1\")\n",
    "ax.set_xticklabels(dfFV.keys(), rotation=90)\n",
    "ax.set_ylabel(\"feature\")\n",
    "ax.legend(ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#accuracy? http://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation\n",
    "from sklearn import metrics as skm\n",
    "\n",
    "print(\"Accuracy: \", skm.accuracy_score(survived_array, kmean.labels_))\n",
    "#[[True Positive, False Negative]]\n",
    "#[[False Positive, True Negative]]\n",
    "print(skm.confusion_matrix(survived_array, kmean.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Why is the rate so bad?\n",
    "labels = kmean.labels_\n",
    "TP = df_reduced[((labels == mask) & (mask==1))]\n",
    "FN = df_reduced[((labels!=mask) & (mask==1))]\n",
    "FP = df_reduced[((labels!=mask) & (mask==0))]\n",
    "TN = df_reduced[((labels==mask) & (mask==0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.scatter(TP[:,0], TP[:,1], color='g', label=\"true positive\")\n",
    "ax.scatter(FN[:,0], FN[:,1], color='m', label=\"false negative\")\n",
    "ax.scatter(FP[:,0], FP[:,1], color='c', label=\"false positive\")\n",
    "ax.scatter(TN[:,0], TN[:,1], color='r', label=\"true negative\")\n",
    "ax.legend(scatterpoints=1, ncol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Challenge\n",
    "=====\n",
    "* What do the clusters look like if there are 3?\n",
    "* What do the clusters look like if init='random'?\n",
    "* What happens if you change a different parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# :/ those results aren't great..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Classification\n",
    "========\n",
    "![super](figs/croppedml.gif)\n",
    "source: Rachel Rakov, originally Andrew Rosenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "#fits on values used for prediction, expected class\n",
    "neigh.fit(dfFV.values, survived.values) \n",
    "print(neigh.score(dfFV.values, survived.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#how do we predict the class of a value? \n",
    "# Note this example is overfitted because the classifier was trained on this data\n",
    "labels = neigh.predict(dfFV)\n",
    "#confusion matrix is:\n",
    "#[[True Positive, False Negative]]\n",
    "#[[False Positive True Negative]]\n",
    "print(skm.confusion_matrix(labels, survived.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "skm.confusion_matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Challenge\n",
    "==========\n",
    "Test out the classifier!\n",
    "\n",
    "1) Download or open the file [`titanictest.csv`](https://github.com/GCDigitalFellows/gcdri_ts_cat_ml/blob/master/data/titanictest.csv)\n",
    "\n",
    "2) Clean it & encode it in the same manner as `titanic.csv` as it's structured the same\n",
    "\n",
    "3) Use the classifier to predict who survived and who didn't\n",
    "\n",
    "4) Test your classifier using the [full training set](https://raw.githubusercontent.com/GCDigitalFellows/gcdri_ts_cat_ml/master/data/titanicfull.csv)\n",
    "\n",
    "5) Evaluate the skill of the classifier on [kaggle](https://www.kaggle.com/c/titanic/submissions/attach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
